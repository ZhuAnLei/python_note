{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "#进度条库\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,       #是静态图片还是连续视频帧\n",
    "    refine_landmarks=True,        #使用Attention Mesh模型，对嘴唇、眼睛、瞳孔周围的关键点精细定位\n",
    "    max_num_faces=1,               #最多检测几张脸\n",
    "    min_detection_confidence=0.5,  #置信度阈值，越接近1越准\n",
    "    min_tracking_confidence=0.5    #追踪阈值\n",
    ")\n",
    "#导入可视化函数和可视化样式\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "#关键点可视化样式\n",
    "landmark_drawing_spec = mp_drawing.DrawingSpec(thickness = 1,circle_radius = 2,color = [66,77,229])\n",
    "#轮廓可视化样式\n",
    "connection_drawing_spec = mp_drawing.DrawingSpec(thickness = 2,circle_radius = 1,color = [223,155,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算左、右眼EAR值以及平均值\n",
    "def computerEar(face_landmarks,height,width):\n",
    "    dics = [33,161,157,133,154,163,362,384,388,263,390,381]\n",
    "    pointarr = []\n",
    "    for dic in dics:\n",
    "        cx = int(face_landmarks.landmark[dic].x * width)\n",
    "        cy = int(face_landmarks.landmark[dic].y * height)\n",
    "        pointarr.append([cx,cy])\n",
    "        #cv2.circle(img, (cx, cy), 5, (0, 0, 255))\n",
    "        #img = cv2.putText(img,str(dic),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1*scaler,(0,255,0),1)\n",
    "    pointarr = np.array(pointarr)\n",
    "\n",
    "    #计算左眼ear\n",
    "    A = np.linalg.norm(pointarr[1]-pointarr[5])\n",
    "    B = np.linalg.norm(pointarr[2]-pointarr[4])\n",
    "    C = np.linalg.norm(pointarr[0]-pointarr[3])\n",
    "    leftear = (A + B) / (2.0 * C) \n",
    "    leftear = round(leftear,2)\n",
    "    #计算右眼ear\n",
    "    D = np.linalg.norm(pointarr[7]-pointarr[11])\n",
    "    E = np.linalg.norm(pointarr[8]-pointarr[10])\n",
    "    F = np.linalg.norm(pointarr[6]-pointarr[9])\n",
    "    rightear = (D + E) / (2.0 * F) \n",
    "    rightear = round(rightear,2)\n",
    "    avaear = (leftear+rightear)/2\n",
    "    avaear = round(avaear,2)\n",
    "    return leftear,rightear,avaear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computermouthear(face_landmarks,height,width):\n",
    "    #dics = [62,39,269,306,405,181]\n",
    "    dics = [62,80,310,306,318,88]\n",
    "    pointarr = []\n",
    "    for dic in dics:\n",
    "        cx = int(face_landmarks.landmark[dic].x * width)\n",
    "        cy = int(face_landmarks.landmark[dic].y * height)\n",
    "        pointarr.append([cx,cy])\n",
    "        #cv2.circle(img, (cx, cy), 5, (0, 0, 255))\n",
    "        #img = cv2.putText(img,str(dic),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1*scaler,(0,255,0),1)\n",
    "    pointarr = np.array(pointarr)\n",
    "    #计算Mouth ear\n",
    "    A = np.linalg.norm(pointarr[1]-pointarr[5])\n",
    "    B = np.linalg.norm(pointarr[2]-pointarr[4])\n",
    "    C = np.linalg.norm(pointarr[0]-pointarr[3])\n",
    "    mouthear = (A + B) / (2.0 * C) \n",
    "    mouthear = round(mouthear,2)\n",
    "    return mouthear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理函数\n",
    "def process_frame(img):\n",
    "    #记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    scaler = 1 #文字大小\n",
    "    h,w = img.shape[0],img.shape[1]\n",
    "    #BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型 获取预测结果\n",
    "    results = model.process(img_RGB)\n",
    "\n",
    "    avaear = 10\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            #绘制人脸网格\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image = img,\n",
    "                landmark_list = face_landmarks,\n",
    "                #connections = mp_face_mesh.FACEMESH_TESSELATION,# 可视化Face Mesh\n",
    "                connections = mp_face_mesh.FACEMESH_CONTOURS,# 可视化脸轮廓\n",
    "                #landmark_drawing_spec 为关键点可视化样式 None为默认值（不显示关键点）\n",
    "                #landmark_drawing_spec= mp_drawing.DrawingSpec(thickness=1,circle_radius=2,color=[66,77,229])\n",
    "                landmark_drawing_spec = landmark_drawing_spec,#关键点圆圈样式\n",
    "                connection_drawing_spec = connection_drawing_spec#轮廓样式\n",
    "            )\n",
    "            \n",
    "            img = cv2.putText(img,'Face Detected',(25*scaler,50*scaler),cv2.FONT_HERSHEY_SIMPLEX,1.25*scaler,(255,0,255),2*scaler)\n",
    "            leftEar,rightEar,averageEar =computerEar(face_landmarks,h,w)\n",
    "            cv2.putText(img, \"Left Eye Aspect Ratio:{}\".format(str(leftEar)), (30*scaler,150*scaler), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(img, \"Right Eye Aspect Ratio:{}\".format(str(rightEar)), (30*scaler,200*scaler), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(img, \"Average Eye Aspect Ratio:{}\".format(str(averageEar)), (30*scaler,250*scaler), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            mouthear = computermouthear(face_landmarks,h,w)\n",
    "            cv2.putText(img, \"Mouth Aspect Ratio:{}\".format(str(mouthear)), (30*scaler,300*scaler), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        img = cv2.putText(img,\"No Face Detected\",(25*scaler,50*scaler),cv2.FONT_HERSHEY_SIMPLEX,1.25*scaler,(255,0,255),2*scaler)\n",
    "\n",
    "    #记录该帧处理完毕时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time-start_time)\n",
    "\n",
    "    img = cv2.putText(img,'FPS  '+str(int(FPS)),(25*scaler,100*scaler),cv2.FONT_HERSHEY_SIMPLEX,1.25*scaler,(255,0,255),2*scaler)\n",
    "\n",
    "    return img,avaear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33左眼左眼角      362右眼左眼角\n",
    "133左眼右眼角     263右眼右眼角\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#使用ipython的魔法方法，将绘制的图像直接嵌入在notebook单元格中\n",
    "%matplotlib inline\n",
    "\n",
    "def look_img(img):\n",
    "    img_RGB = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawimg = cv2.imread('data/4.jpg')\n",
    "# processimg = process_frame(rawimg)\n",
    "# look_img(processimg)\n",
    "# cv2.imwrite('4_out.jpg',processimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# 眨眼最小阈值  触发报警的眼睛纵横比的最小阈值\n",
    "eyes_blink = 0.1\n",
    "# 眼睛比率低于触发警报阈值的最小连续帧\n",
    "eyes_ratio = 50\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.open(0)\n",
    "#无限循环，知道break被触发\n",
    "while cap.isOpened():\n",
    "    success ,frame = cap.read()\n",
    "    if not success:\n",
    "        print('ERROR')\n",
    "        break\n",
    "\n",
    "    ### 处理帧函数\n",
    "    frame,curavaear = process_frame(frame)\n",
    "    #展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或者esc退出（在英文输入法下）\n",
    "        break\n",
    "\n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40bf029a4ce719e9e7f415950efd66bd68c4942ca9c8d1259739badff8e4d6af"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
